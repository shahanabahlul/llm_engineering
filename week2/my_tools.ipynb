{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddfa9ae6-69fe-444a-b994-8c4c5970a7ec",
   "metadata": {},
   "source": [
    "# Project - PPTX summarizer AI Assistant\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b50bbe2-c0b1-49c3-9a5c-1ba7efa2bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "747e8786-9da8-4342-b6c9-f5f69c2e22ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "MODEL = \"gpt-4o-mini\"\n",
    "openai = OpenAI()\n",
    "\n",
    "# As an alternative, if you'd like to use Ollama instead of OpenAI\n",
    "# Check that Ollama is running for you locally (see week1/day2 exercise) then uncomment these next 2 lines\n",
    "# MODEL = \"llama3.2\"\n",
    "# openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bac7ac31-6ece-4aa1-87eb-329b82f0f45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from pptx import Presentation\n",
    "import openai  # adapt if you use a different client\n",
    "\n",
    "class PptxSummary:\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "\n",
    "    def summary(self):\n",
    "        # Load an existing PowerPoint\n",
    "        prs = Presentation(self.name)\n",
    "        newtext = \"\"\n",
    "\n",
    "        # print(prs)\n",
    "        # Loop over all slides\n",
    "        for i, slide in enumerate(prs.slides, start=1):\n",
    "            # print(f\"\\n--- Slide {i} ---\")\n",
    "            newtext += f\"\\n\\n--- Slide {i} ---\"\n",
    "            \n",
    "            # Loop over shapes (text boxes, titles, placeholders, etc.)\n",
    "            for shape in slide.shapes:\n",
    "                if shape.has_text_frame:  # Only shapes that can contain text\n",
    "                    for paragraph in shape.text_frame.paragraphs:\n",
    "                        # Collect text from each run in the paragraph\n",
    "                        text = \"\".join(run.text for run in paragraph.runs)\n",
    "                        # print(text)\n",
    "                        newtext+= \"\\n\"\n",
    "                        newtext += text\n",
    "        # print(newtext)\n",
    "        return newtext\n",
    "\n",
    "        \n",
    "# Standalone function the way you requested\n",
    "# def summarize_ppt(name):\n",
    "#     \"\"\"\n",
    "#     External helper: given a PPT filename (with or without .pptx) and a directory,\n",
    "#     returns a PptxSummary object with .content filled by the LLM summary.\n",
    "#     Throws FileNotFoundError if file not found.\n",
    "#     \"\"\"\n",
    "#     # resolve path\n",
    "\n",
    "\n",
    "# print(summarization_message)\n",
    "system_message = \"You are a helpful assistant for a company and you can summarize the given topic based on the given pptx name. \"\n",
    "system_message += \"Give short, courteous answers, no more than 10 sentence. \"\n",
    "system_message += \"Always be accurate. If the presentation .pptx file does not exist, say so. Respond in markdown.\"\n",
    "\n",
    "def user_message(path):\n",
    "    ppt = PptxSummary(path)\n",
    "    summarization_message = ppt.summary()\n",
    "    message = \"You need to summarize the a pptx file.\"\n",
    "    message += f\"The context of that pptx file is here: {summarization_message}\"\n",
    "    message += \"Give the concise information in small paragraphs. \"\n",
    "    return message\n",
    "\n",
    "def pptx_summary(path):\n",
    "    if os.path.exists(path):\n",
    "        result = \"The file does not exist\"\n",
    "        response = openai.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": user_message(path)}\n",
    "              ],\n",
    "        )\n",
    "        result = response.choices[0].message.content\n",
    "        return result\n",
    "    else:\n",
    "        return \"The file does not exist\"\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# messages = [{\"role\": \"system\", \"content\": system_message, \"role\": \"user\", \"content\": user_message}]\n",
    "# response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "# result = response.choices[0].message.content\n",
    "# display(Markdown(result))\n",
    "# import os\n",
    "\n",
    "# print(\"Current working directory:\", os.getcwd())\n",
    "# print(\"Files here:\", os.listdir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4747d6b-d224-4ab3-b9bb-81c423497c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Summary of \"Marie Curie: Highlights of a Notable Life\"\n",
      "\n",
      "Marie Curie, born in Warsaw, Poland in 1867, was a pioneering scientist who made significant contributions to the fields of physics and chemistry. She studied in Paris, where she began her groundbreaking work.\n",
      "\n",
      "One of her most notable achievements includes being the first woman to win a Nobel Prize. Alongside her husband, Pierre Curie, she discovered the concept of radioactivity and later won Nobel Prizes in both Physics and Chemistry, solidifying her status in the scientific community.\n",
      "\n",
      "Curie's legacy extends far beyond her awards; she paved the way for women in science and significantly impacted medical technology, particularly in the development of X-ray applications. Her work has made her one of the most influential scientists in history.\n"
     ]
    }
   ],
   "source": [
    "print(pptx_summary(\"Marie_Curie.pptx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd2b368-960c-40b4-adf0-db40fe713cbc",
   "metadata": {},
   "source": [
    "# My tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f7c0fda-704b-4e3d-bc69-89986cf5e7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file does not exist\n"
     ]
    }
   ],
   "source": [
    "print(pptx_summary(\"bts.pptx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f8e54f-af95-4bf6-a202-89e7a3ffdec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36bedabf-a0a7-4985-ad8e-07ed6a55a3a4",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "Tools are an incredibly powerful feature provided by the frontier LLMs.\n",
    "\n",
    "With tools, you can write a function, and have the LLM call that function as part of its response.\n",
    "\n",
    "Sounds almost spooky.. we're giving it the power to run code on our machine?\n",
    "\n",
    "Well, kinda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4afceded-7178-4c05-8fa6-9f2085e6a344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's a particular dictionary structure that's required to describe our function:\n",
    "\n",
    "summary_function = {\n",
    "    \"name\": \"pptx_summary\",\n",
    "    \"description\": \"Get the summary for the given pptx file, you need to call this function, if user asks for a pptx file, if it is outside of the pptx file, tell that you do not know.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"path\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The name of the presentation\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"path\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdca8679-935f-4e7f-97e6-e71a4d4f228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And this is included in a list of tools:\n",
    "\n",
    "tools = [{\"type\": \"function\", \"function\": summary_function}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d3554f-b4e3-4ce7-af6f-68faa6dd2340",
   "metadata": {},
   "source": [
    "## Getting OpenAI to use our Tool\n",
    "\n",
    "There's some fiddly stuff to allow OpenAI \"to call our tool\"\n",
    "\n",
    "What we actually do is give the LLM the opportunity to inform us that it wants us to run the tool.\n",
    "\n",
    "Here's how the new chat function looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce9b0744-9c78-408d-b9df-9f6fd9ed78cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "\n",
    "    if response.choices[0].finish_reason==\"tool_calls\":\n",
    "        message = response.choices[0].message\n",
    "        print(f\"message: {message}\")\n",
    "        response, city = handle_tool_call(message)\n",
    "        print(f\"city: {city}, response: {response}\")\n",
    "        messages.append(message)\n",
    "        messages.append(response)\n",
    "        response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "        print(f\"response: {response}\")\n",
    "            \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0992986-ea09-4912-a076-8e5603ee631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to write that function handle_tool_call:\n",
    "\n",
    "def handle_tool_call(message):\n",
    "    tool_call = message.tool_calls[0]\n",
    "    print(f\"tool_call: {tool_call}\")\n",
    "    arguments = json.loads(tool_call.function.arguments)\n",
    "    print(f\"arguments: {arguments}\")\n",
    "    path = arguments.get('path')\n",
    "    print(f\"path: {path}\")\n",
    "    summary = pptx_summary(path)\n",
    "    # print(f\"price: {price}\")\n",
    "    response = {\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": json.dumps({\"path\": path,\"summary\": summary}),\n",
    "        \"tool_call_id\": tool_call.id\n",
    "    }\n",
    "    print(f\"response: {response}\")\n",
    "    return response, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4be8a71-b19e-4c2f-80df-f59ff2661f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d551ce21-c66c-4f56-88ad-8212f16437ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
